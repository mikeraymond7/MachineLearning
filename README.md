# *MachineLearning*
Projects and Presentations for Machine Learning Course at Hofstra University in collaboration with Cynthia Zhao

## **Final Project**  
Our cumulative project utilized web scraping, data cleaning, clustering, and supervised learning in order to predict the abilities of current draft prospects against all-time leaders in batting statistics for Major League Baseball.

## **Kaggle Competition**  
The Kaggle Competition was an in-class competition in which each student attempted to use stock data and the fact of whether or not the user chose a given stock to train a model and predict what other stocks would be chosen. My personal implementation placed 5th out of 31 students.

## **Project 3**  
Project 3 introduced RMSE, Feature Engineering, clustering, and nearest neighbor calculations to create better investments in the stock market based on comparisons between company trends.

## **Project 2**  
**Project 2** utilized Amazon Kindle Unlimited Data over Time Series and a number of other models to ensure the most desireable books are always in the store.  

## **Project 1**  
**Project 1** introduced basic data mining techniques and the Jaccard Similarity to compare the likenesses of different ETFs based on major holdings.

### Presentations Link  
To see our presentations and conclusions on each project (except the kaggle competition), please find each video in the link below:
- https://drive.google.com/drive/folders/1sBcAQNsRDdxefNIyTzuHBvykpfelc-8N?usp=sharing

#### Note:
- The original Google Colab files reside on university accounts and will both be disabled. This acts as an archive for our final work. The link above will be available, but colab links within the files on this repository may not be accessible in the future.
- Projects are listed in order of importance. That is, Project 1 is quite basic while the Final Project is naturally more advanced. 
- The presentations will greatly assist in the understanding of each colab!
